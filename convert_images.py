import os
import json
import requests
from PIL import Image
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse
import time

class ImageConverter:
    def __init__(self, quality=80, max_width=1920):
        """
        quality: Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© (1-100) - ÙƒÙ„ Ù…Ø§ Ù‚Ù„ Ø§Ù„Ø±Ù‚Ù… ÙƒÙ„ Ù…Ø§ Ø§Ù„Ø­Ø¬Ù… ØµØºØ±
        max_width: Ø£Ù‚ØµÙ‰ Ø¹Ø±Ø¶ Ù„Ù„ØµÙˆØ±Ø© Ø¨Ø§Ù„Ø¨ÙƒØ³Ù„
        """
        self.quality = quality
        self.max_width = max_width
        self.success_count = 0
        self.failed_count = 0
        self.total_original_size = 0
        self.total_converted_size = 0
        
    def download_image(self, url, timeout=10):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=timeout)
            response.raise_for_status()
            return response.content
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„: {url[:50]}... - {str(e)}")
            return None
    
    def resize_image(self, img):
        """ØªØµØºÙŠØ± Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ÙƒØ¨ÙŠØ±Ø©"""
        width, height = img.size
        if width > self.max_width:
            ratio = self.max_width / width
            new_height = int(height * ratio)
            img = img.resize((self.max_width, new_height), Image.Resampling.LANCZOS)
        return img
    
    def convert_to_webp(self, image_data, output_path):
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ WebP"""
        try:
            # ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø©
            img = Image.open(BytesIO(image_data))
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ RGB Ø¥Ø°Ø§ ÙƒØ§Ù†Øª RGBA
            if img.mode in ('RGBA', 'LA', 'P'):
                background = Image.new('RGB', img.size, (255, 255, 255))
                if img.mode == 'P':
                    img = img.convert('RGBA')
                background.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
                img = background
            elif img.mode != 'RGB':
                img = img.convert('RGB')
            
            # ØªØµØºÙŠØ± Ø§Ù„Ø­Ø¬Ù…
            img = self.resize_image(img)
            
            # Ø­ÙØ¸ ÙƒÙ€ WebP
            img.save(output_path, 'WEBP', quality=self.quality, method=6)
            
            return True
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„: {str(e)}")
            return False
    
    def process_single_image(self, url, output_dir, filename):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø©"""
        if not url or url == 'None':
            return None
        
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
            image_data = self.download_image(url)
            if not image_data:
                self.failed_count += 1
                return None
            
            original_size = len(image_data)
            self.total_original_size += original_size
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯
            os.makedirs(output_dir, exist_ok=True)
            
            # Ù…Ø³Ø§Ø± Ø§Ù„Ø­ÙØ¸
            output_path = os.path.join(output_dir, filename)
            
            # Ø§Ù„ØªØ­ÙˆÙŠÙ„
            if self.convert_to_webp(image_data, output_path):
                converted_size = os.path.getsize(output_path)
                self.total_converted_size += converted_size
                self.success_count += 1
                
                reduction = ((original_size - converted_size) / original_size) * 100
                print(f"âœ“ {filename}: {original_size/1024:.1f}KB â†’ {converted_size/1024:.1f}KB (ØªÙˆÙÙŠØ± {reduction:.1f}%)")
                
                return output_path
            else:
                self.failed_count += 1
                return None
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© {filename}: {str(e)}")
            self.failed_count += 1
            return None
    
    def process_media_data(self, json_file, output_base_dir, media_type='movies'):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù JSON Ù„Ù„Ø£ÙÙ„Ø§Ù… Ø£Ùˆ Ø§Ù„Ù…Ø³Ù„Ø³Ù„Ø§Øª"""
        print(f"\n{'='*60}")
        print(f"ğŸ¬ Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© {media_type.upper()}")
        print(f"{'='*60}\n")
        
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        with open(json_file, 'r', encoding='utf-8') as f:
            media_data = json.load(f)
        
        total_items = len(media_data)
        print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹Ù†Ø§ØµØ±: {total_items}\n")
        
        updated_data = []
        tasks = []
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
        posters_dir = os.path.join(output_base_dir, media_type, 'posters')
        backdrops_dir = os.path.join(output_base_dir, media_type, 'backdrops')
        logos_dir = os.path.join(output_base_dir, media_type, 'logos')
        
        # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…Ù‡Ø§Ù…
        for idx, item in enumerate(media_data, 1):
            title = item.get('title', f'item_{idx}')
            safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).strip()
            safe_title = safe_title[:50]  # ØªØ­Ø¯ÙŠØ¯ Ø·ÙˆÙ„ Ø§Ù„Ø§Ø³Ù…
            
            item_tasks = {
                'poster': (item.get('poster'), posters_dir, f"{idx}_{safe_title}_poster.webp"),
                'backdrop': (item.get('backdrop'), backdrops_dir, f"{idx}_{safe_title}_backdrop.webp"),
                'logo': (item.get('logo'), logos_dir, f"{idx}_{safe_title}_logo.webp")
            }
            
            tasks.append((idx, item, item_tasks))
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø®ÙŠÙˆØ·
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = []
            
            for idx, item, item_tasks in tasks:
                future_map = {}
                for img_type, (url, output_dir, filename) in item_tasks.items():
                    if url and url != 'None':
                        future = executor.submit(self.process_single_image, url, output_dir, filename)
                        future_map[future] = (idx, img_type, filename)
                        futures.append(future)
                
                # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‡Ø§Ù…
                item['_futures'] = future_map
            
            # Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            completed = 0
            for future in as_completed(futures):
                completed += 1
                result = future.result()
                
                if completed % 10 == 0:
                    print(f"\nğŸ“ˆ Ø§Ù„ØªÙ‚Ø¯Ù…: {completed}/{len(futures)} ({(completed/len(futures)*100):.1f}%)\n")
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        for idx, item, item_tasks in tasks:
            new_item = {
                'title': item['title'],
                'poster': None,
                'backdrop': None,
                'logo': None
            }
            
            for img_type, (url, output_dir, filename) in item_tasks.items():
                if url and url != 'None':
                    new_path = os.path.join(output_dir, filename)
                    if os.path.exists(new_path):
                        new_item[img_type] = new_path
            
            updated_data.append(new_item)
        
        # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø«Ø©
        output_json = json_file.replace('.json', '_webp.json')
        with open(output_json, 'w', encoding='utf-8') as f:
            json.dump(updated_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ“ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø«Ø© ÙÙŠ: {output_json}")
        
        return updated_data
    
    def print_summary(self):
        """Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©"""
        print(f"\n{'='*60}")
        print("ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")
        print(f"{'='*60}")
        print(f"âœ“ Ù†Ø¬Ø­: {self.success_count} ØµÙˆØ±Ø©")
        print(f"âŒ ÙØ´Ù„: {self.failed_count} ØµÙˆØ±Ø©")
        print(f"ğŸ“¦ Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø£ØµÙ„ÙŠ: {self.total_original_size/1024/1024:.2f} Ù…ÙŠØ¬Ø§")
        print(f"ğŸ“¦ Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯: {self.total_converted_size/1024/1024:.2f} Ù…ÙŠØ¬Ø§")
        
        if self.total_original_size > 0:
            saved = self.total_original_size - self.total_converted_size
            percentage = (saved / self.total_original_size) * 100
            print(f"ğŸ’¾ ØªÙˆÙÙŠØ±: {saved/1024/1024:.2f} Ù…ÙŠØ¬Ø§ ({percentage:.1f}%)")
        print(f"{'='*60}\n")


def main():
    """Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
    print("ğŸ¨ Ø¨Ø±Ù†Ø§Ù…Ø¬ ØªØ­ÙˆÙŠÙ„ ÙˆØ¶ØºØ· Ø§Ù„ØµÙˆØ± Ø¥Ù„Ù‰ WebP")
    print("="*60)
    
    # Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    converter = ImageConverter(
        quality=75,      # Ø¬ÙˆØ¯Ø© 75% (Ù…Ù…ØªØ§Ø²Ø© ÙˆÙ…Ø¶ØºÙˆØ·Ø©)
        max_width=1920   # Ø£Ù‚ØµÙ‰ Ø¹Ø±Ø¶ 1920 Ø¨ÙƒØ³Ù„
    )
    
    output_dir = "converted_images"
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£ÙÙ„Ø§Ù…
    if os.path.exists('movies_data.json'):
        print("\nğŸ¬ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£ÙÙ„Ø§Ù…...")
        converter.process_media_data('movies_data.json', output_dir, 'movies')
    else:
        print("âš ï¸ Ù…Ù„Ù movies_data.json ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ù„Ø³Ù„Ø§Øª
    if os.path.exists('series_data.json'):
        print("\nğŸ“º Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ù„Ø³Ù„Ø§Øª...")
        converter.process_media_data('series_data.json', output_dir, 'series')
    else:
        print("âš ï¸ Ù…Ù„Ù series_data.json ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
    
    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    converter.print_summary()
    
    print("âœ… ØªÙ…Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!")
    print(f"ğŸ“ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ: {os.path.abspath(output_dir)}")


if __name__ == "__main__":
    main()